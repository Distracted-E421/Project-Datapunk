{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frciLeqnOKSi"
      },
      "outputs": [],
      "source": [
        "!pip -q install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "-Mx6rJPYQgjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## basic example"
      ],
      "metadata": {
        "id": "Wr10mIsQQeb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama3-groq-70b-8192-tool-use-preview\n",
        "llama3-groq-8b-8192-tool-use-preview"
      ],
      "metadata": {
        "id": "_9oWCEHjVYfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbipaKMqQeHP",
        "outputId": "f36afc74-ef6c-46d2-87cc-39271ff33474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are essential for various applications in natural language processing (NLP) due to their ability to process and generate text quickly. Here are some reasons why they are important:\n",
            "\n",
            "1. **Real-time Processing**: Fast language models enable real-time processing of text, which is crucial for applications that require immediate responses, such as chatbots, virtual assistants, and live transcription services.\n",
            "2. **Scalability**: They can handle large volumes of text efficiently, making them ideal for big data applications and tasks that involve processing massive amounts of text.\n",
            "3. **Speed of Development**: Fast language models accelerate the development of NLP applications by providing a foundation for rapid prototyping and testing.\n",
            "4. **Improved User Experience**: By responding quickly, fast language models enhance the user experience in applications like customer service, where fast resolution is key.\n",
            "5. **Enhanced Analytics**: They facilitate the analysis of large datasets, enabling insights that might not be possible with slower models.\n",
            "6. **Support for Multitasking**: Fast language models can handle multiple tasks simultaneously, making them suitable for applications that require concurrent processing.\n",
            "7. **Advancements in AI Research**: The development of fast language models drives innovation in AI research, pushing the boundaries of what is possible in NLP.\n",
            "\n",
            "In summary, fast language models are vital for applications that require rapid text processing, scalability, and efficient development. They have far-reaching implications for various industries and continue to shape the future of NLP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tool Use with Groq**"
      ],
      "metadata": {
        "id": "PG2waQLCWOUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import json\n",
        "\n",
        "client = Groq()\n",
        "MODEL = 'llama3-groq-70b-8192-tool-use-preview'\n",
        "\n",
        "def calculate(expression):\n",
        "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        print(expression)\n",
        "        return json.dumps({\"result\": result})\n",
        "    except:\n",
        "        return json.dumps({\"error\": \"Invalid expression\"})\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"calculate\",\n",
        "                \"description\": \"Evaluate a mathematical expression\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"expression\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The mathematical expression to evaluate\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"expression\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    if tool_calls:\n",
        "        available_functions = {\n",
        "            \"calculate\": calculate,\n",
        "        }\n",
        "        messages.append(response_message)\n",
        "        for tool_call in tool_calls:\n",
        "            print(tool_call)\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                expression=function_args.get(\"expression\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "        second_response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages\n",
        "        )\n",
        "        return second_response.choices[0].message.content\n",
        "\n",
        "user_prompt = \"What is 25 x 4 + 10 - 9.11?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BVdjacgWIh3",
        "outputId": "90631176-e112-469a-f93b-46a50fa3c2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_7d4b', function=Function(arguments='{\"expression\": \"25*4+10-9.11\"}', name='calculate'), type='function')\n",
            "25*4+10-9.11\n",
            "The result of 25 x 4 + 10 - 9.11 is 100.89.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What is 6 squared?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "id": "qk18Xr6TWWLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e571fdc-b75f-41ae-f35b-1d43e0d1394e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_6nys', function=Function(arguments='{\"expression\": \"6^2\"}', name='calculate'), type='function')\n",
            "6^2\n",
            "6 squared is 36.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What is 25 times 4 plus ten?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKWoRtEvcqgf",
        "outputId": "1b3cbe79-f0b7-4b1d-921a-7049d60bc6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_2x9a', function=Function(arguments='{\"expression\": \"25*4+10\"}', name='calculate'), type='function')\n",
            "25*4+10\n",
            "The result of 25 times 4 plus 10 is 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"How are you today?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9yls_zGeZkH",
        "outputId": "ff970be5-3192-43ac-c737-0b0b7e8bbfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install wikipedia duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiGFMyQtc5tO",
        "outputId": "0625fba4-b223-4ced-d48b-a3ef9e008764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import json\n",
        "import requests\n",
        "import wikipedia\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "client = Groq()\n",
        "MODEL = 'llama3-groq-70b-8192-tool-use-preview'\n",
        "\n",
        "def duckduckgo_search(query):\n",
        "    \"\"\"Perform a DuckDuckGo search using the duckduckgo_search library\"\"\"\n",
        "    print(f\"Using DuckDuckGo for {query}\")\n",
        "\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            results = list(ddgs.text(query, max_results=3))\n",
        "\n",
        "        if not results:\n",
        "            return f\"No results found for '{query}'. The search may have been too specific or there might be no relevant information available.\"\n",
        "\n",
        "        formatted_results = \"\\n\".join([f\"- {result['title']}: {result['body']}\" for result in results])\n",
        "        return f\"Here are some search results for '{query}':\\n{formatted_results}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred while searching for '{query}': {str(e)}\"\n",
        "\n",
        "def wikipedia_search(query):\n",
        "    \"\"\"Perform a Wikipedia search\"\"\"\n",
        "    try:\n",
        "        print(f\"Using Wikipedia for {query}\")\n",
        "        page = wikipedia.page(query)\n",
        "        summary = wikipedia.summary(query, sentences=2)\n",
        "        return json.dumps({\"title\": page.title, \"summary\": summary, \"url\": page.url})\n",
        "    except:\n",
        "        return json.dumps({\"error\": \"No Wikipedia page found for the query\"})\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a search assistant. Use the duckduckgo_search function to perform web \\\n",
        "            searches and the wikipedia_search function to find information on Wikipedia. if you don't \\\n",
        "            need either of these then just reply normally\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"duckduckgo_search\",\n",
        "                \"description\": \"Perform a DuckDuckGo search\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The search query\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"wikipedia_search\",\n",
        "                \"description\": \"Perform a Wikipedia search\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The search query\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    if tool_calls:\n",
        "        available_functions = {\n",
        "            \"duckduckgo_search\": duckduckgo_search,\n",
        "            \"wikipedia_search\": wikipedia_search,\n",
        "        }\n",
        "        messages.append(response_message)\n",
        "        for tool_call in tool_calls:\n",
        "            print(tool_call)\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                query=function_args.get(\"query\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "        second_response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages\n",
        "        )\n",
        "        return second_response.choices[0].message.content\n",
        "\n",
        "user_prompt = \"What is the capital of France and what's a famous landmark there?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1wtWsdPdCjO",
        "outputId": "d6b7c9ea-b9b1-42ae-877a-67144bc1674a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_2j7f', function=Function(arguments='{\"query\": \"capital of France\"}', name='wikipedia_search'), type='function')\n",
            "Using Wikipedia for capital of France\n",
            "ChatCompletionMessageToolCall(id='call_k96v', function=Function(arguments='{\"query\": \"famous landmark in France\"}', name='wikipedia_search'), type='function')\n",
            "Using Wikipedia for famous landmark in France\n",
            "The capital of France is Paris. A famous landmark there is the Eiffel Tower, which is an iconic symbol of France and one of the most recognizable structures in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What are the latest news headlines about artificial intelligence?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8e6gzr1enKF",
        "outputId": "cb699340-4ff9-4974-a16d-32e8afee6e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_884h', function=Function(arguments='{\"query\": \"latest news on artificial intelligence\"}', name='duckduckgo_search'), type='function')\n",
            "Using DuckDuckGo for latest news on artificial intelligence\n",
            "Here are the latest news headlines on artificial intelligence:\n",
            "1. \"AI News | Latest Headlines and Developments | Reuters\" - July 11, 2024, covering how customers have booked out South Korean cosmetics giant AmorePacific's new artificial intelligence beauty lab.\n",
            "2. \"Exclusive: OpenAI working on new reasoning technology under code name 'Strawberry'.\" - OpenAI is working on a novel approach to its artificial intelligence models.\n",
            "3. \"AI News & Artificial Intelligence | TechCrunch\" - TechCrunch covers the latest news and trends on artificial intelligence and machine learning tech, including generative AI, speech recognition, and predictive analytics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Tell me about the company Groq?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38_DYiK9dWMe",
        "outputId": "68f12d6b-4302-4941-a4a1-0bc9fd38e627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"How are you today?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n0Y_kDud7cW",
        "outputId": "c0d5e424-e342-45af-cb2d-5dece19fb4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import wikipedia\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "MODEL = 'llama3-groq-70b-8192-tool-use-preview'\n",
        "\n",
        "def duckduckgo_search(query):\n",
        "    \"\"\"Perform a DuckDuckGo search using the duckduckgo_search library\"\"\"\n",
        "    print(f\"Using DuckDuckGo for {query}\")\n",
        "\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            results = list(ddgs.text(query, max_results=3))\n",
        "\n",
        "        if not results:\n",
        "            return f\"No results found for '{query}'. The search may have been too specific or there might be no relevant information available.\"\n",
        "\n",
        "        formatted_results = \"\\n\".join([f\"- {result['title']}: {result['body']}\" for result in results])\n",
        "        return f\"Here are some search results for '{query}':\\n{formatted_results}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred while searching for '{query}': {str(e)}\"\n",
        "\n",
        "def wikipedia_search(query):\n",
        "    \"\"\"Perform a Wikipedia search\"\"\"\n",
        "    try:\n",
        "        print(f\"Using Wikipedia for {query}\")\n",
        "        page = wikipedia.page(query)\n",
        "        summary = wikipedia.summary(query, sentences=2)\n",
        "        return f\"Wikipedia article: {page.title}\\nSummary: {summary}\\nURL: {page.url}\"\n",
        "    except:\n",
        "        return f\"No Wikipedia page found for the query '{query}'\"\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a search assistant. Use the duckduckgo_search function to perform web \\\n",
        "            searches and the wikipedia_search function to find information on Wikipedia. If you don't \\\n",
        "            need either of these then just reply normally. When using search results, summarize and \\\n",
        "            integrate the information into your response.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"duckduckgo_search\",\n",
        "                \"description\": \"Perform a DuckDuckGo search\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The search query\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"wikipedia_search\",\n",
        "                \"description\": \"Perform a Wikipedia search\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The search query\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    if tool_calls:\n",
        "        available_functions = {\n",
        "            \"duckduckgo_search\": duckduckgo_search,\n",
        "            \"wikipedia_search\": wikipedia_search,\n",
        "        }\n",
        "        messages.append(response_message)\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                query=function_args.get(\"query\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "        second_response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages\n",
        "        )\n",
        "        return second_response.choices[0].message.content\n",
        "    else:\n",
        "        return response_message.content\n",
        "\n",
        "# Example usage\n",
        "user_prompt = \"What are the latest news headlines about artificial intelligence?\"\n",
        "print(run_conversation(user_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRTmpma7fKf0",
        "outputId": "f9896daa-acf5-42b1-adde-02bbde507696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using DuckDuckGo for latest news on artificial intelligence\n",
            "Here are the latest news headlines on artificial intelligence:\n",
            "1. OpenAI is working on a new project called \"Strawberry,\" which involves a novel approach to AI technology.\n",
            "2. In South Korea, a new AI beauty lab has been fully booked, where robots custom mix face products using the latest technology.\n",
            "3. OpenAI has introduced a set of levels to track progress towards building superintelligent AI, a significant step in monitoring AI advancements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"How are you today?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv7uLIYgfODF",
        "outputId": "c87060ff-d506-4c39-f55f-10a44ba2e1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm doing well, thank you for asking. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"please search and tell me about the company Groq.com?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP-aCSujfRLI",
        "outputId": "8f7eb932-f0a4-4b5d-f302-a6369fb5b100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Wikipedia for Groq.com\n",
            "Using DuckDuckGo for Groq.com\n",
            "Based on the information I found, Groq, Inc. is an American artificial intelligence (AI) company that builds an AI accelerator application-specific integrated circuit (ASIC) called the Language Processing Unit (LPU) and related hardware to accelerate the inference performance of AI workloads. They provide cloud and on-premises solutions at scale for AI applications, with a headquarters in Silicon Valley and founded in 2016. The LPU and related systems are designed, fabricated, and assembled in North America. Additionally, GroqCloud provides the world's fastest AI inference for large language models (LLMs) via its Groq LPU Inference Engine. You can access the GroqCloud API for enterprise, public sector, and developer projects, and compare prices and performance with other providers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What are the latest news headlines about artificial intelligence?\"\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mz-WXQDfUYH",
        "outputId": "befdc221-4c19-4584-f1f1-7a32ac8d8e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using DuckDuckGo for latest news on artificial intelligence\n",
            "Here are the latest news headlines on artificial intelligence:\n",
            "1. \"AI News | Latest Headlines and Developments | Reuters\": This article discusses how customers have booked out South Korean cosmetics giant AmorePacific's new artificial intelligence beauty lab, where robots custom mix face products and the latest technology recommends the most suitable skincare routines.\n",
            "2. \"Exclusive: OpenAI working on new reasoning technology under code name 'Strawberry'\": OpenAI, the maker of ChatGPT, is working on a novel approach to its artificial intelligence models in a project code-named 'Strawberry', according to a person familiar with the matter and internal documents.\n",
            "3. \"OpenAI Sets Levels to Track Progress Toward Superintelligent AI - Bloomberg\": OpenAI has come up with a set of five levels to track its progress toward building artificial intelligence software capable of outperforming humans, the startup's latest effort to help people understand the potential risks and rewards of advanced AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import wikipedia\n",
        "from groq import Groq\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "client = Groq()\n",
        "MODEL = 'llama3-groq-70b-8192-tool-use-preview'\n",
        "\n",
        "\n",
        "\n",
        "def duckduckgo_search(query):\n",
        "    \"\"\"Perform a DuckDuckGo search using the duckduckgo_search library\"\"\"\n",
        "    print(f\"Using DuckDuckGo for {query}\")\n",
        "\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            results = list(ddgs.text(query, max_results=3))\n",
        "\n",
        "        if not results:\n",
        "            return f\"No results found for '{query}'. The search may have been too specific or there might be no relevant information available.\"\n",
        "\n",
        "        formatted_results = \"\\n\".join([f\"- {result['title']}: {result['body']}\" for result in results])\n",
        "        return f\"Here are some search results for '{query}':\\n{formatted_results}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred while searching for '{query}': {str(e)}\"\n",
        "\n",
        "def wikipedia_search(query):\n",
        "    \"\"\"Perform a Wikipedia search\"\"\"\n",
        "    try:\n",
        "        print(f\"Using Wikipedia for {query}\")\n",
        "        page = wikipedia.page(query)\n",
        "        summary = wikipedia.summary(query, sentences=2)\n",
        "        return f\"Wikipedia article: {page.title}\\nSummary: {summary}\\nURL: {page.url}\"\n",
        "    except:\n",
        "        return f\"No Wikipedia page found for the query '{query}'\"\n",
        "\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a search assistant. Use the internet_search function to perform web \\\n",
        "            searches and the wikipedia_search function to find information on Wikipedia. You can use \\\n",
        "            multiple tools if needed. If you don't need either of these then just reply normally. \\\n",
        "            When using search results, summarize and integrate the information into your response.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"internet_search\",\n",
        "                \"description\": \"use this to search about a topic on the internet\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The search query\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"wikipedia_search\",\n",
        "                \"description\": \"Perform a Wikipedia search\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The search query\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"query\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    available_functions = {\n",
        "        \"internet_search\": duckduckgo_search,\n",
        "        \"wikipedia_search\": wikipedia_search,\n",
        "    }\n",
        "\n",
        "    tool_outputs = []\n",
        "    max_iterations = 3  # Limit the number of tool calls to prevent infinite loops\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice=\"auto\",\n",
        "            max_tokens=4096\n",
        "        )\n",
        "\n",
        "        response_message = response.choices[0].message\n",
        "        tool_calls = response_message.tool_calls\n",
        "\n",
        "        if not tool_calls:\n",
        "            # If no more tool calls are needed, return the final response\n",
        "            return {\n",
        "                \"final_response\": response_message.content,\n",
        "                \"tool_outputs\": tool_outputs\n",
        "            }\n",
        "\n",
        "        messages.append(response_message)\n",
        "\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                query=function_args.get(\"query\")\n",
        "            )\n",
        "            tool_outputs.append({\n",
        "                \"tool\": function_name,\n",
        "                \"query\": function_args.get(\"query\"),\n",
        "                \"result\": function_response\n",
        "            })\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # If we've reached the maximum number of iterations, return the last response\n",
        "    return {\n",
        "        \"final_response\": \"Maximum number of tool calls reached. Here's the last response:\\n\" + response_message.content,\n",
        "        \"tool_outputs\": tool_outputs\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "user_prompt = \"Compare the latest AI developments in healthcare and finance. Include specific examples from recent news.\"\n",
        "result = run_conversation(user_prompt)\n",
        "print(\"Final Response:\", result[\"final_response\"])\n",
        "print(\"\\nTool Outputs:\")\n",
        "for output in result[\"tool_outputs\"]:\n",
        "    print(f\"\\nTool: {output['tool']}\")\n",
        "    print(f\"Query: {output['query']}\")\n",
        "    print(f\"Result: {output['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uobpqxr1u5dD",
        "outputId": "dcea6e14-fc52-48a1-eef6-3fdd7105c19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using DuckDuckGo for latest AI developments in healthcare\n",
            "Using DuckDuckGo for latest AI developments in finance\n",
            "Final Response: Based on the latest news, AI is transforming both healthcare and finance by improving outcomes, patient safety, and the accessibility of high-quality care in healthcare, and by potentially reshaping the finance industry, making it more efficient and accessible. For instance, in healthcare, AI is being used to improve diagnostics, patient care, and health management. In finance, AI is enhancing fraud detection, personalizing customer service, and optimizing financial models.\n",
            "\n",
            "Tool Outputs:\n",
            "\n",
            "Tool: internet_search\n",
            "Query: latest AI developments in healthcare\n",
            "Result: Here are some search results for 'latest AI developments in healthcare':\n",
            "- The potential for artificial intelligence to transform healthcare ...: Artificial intelligence (AI) has the potential to transform care delivery by improving health outcomes, patient safety, and the affordability and accessibility of high-quality care.\n",
            "- Artificial intelligence in healthcare: transforming the practice of ...: Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction ...\n",
            "- AI in health and medicine - Nature: AI has the potential to reshape medicine and make healthcare more accurate, efficient and accessible; this Review discusses recent progress, opportunities and challenges toward achieving this goal.\n",
            "\n",
            "Tool: internet_search\n",
            "Query: latest AI developments in finance\n",
            "Result: Here are some search results for 'latest AI developments in finance':\n",
            "- What the Finance Industry Tells Us About the Future of AI: The meteoric rise of artificial intelligence (AI) in the public conscience has caused many people to question what an AI-dominated future looks like. Will AI transform industries?\n",
            "- The future of AI in banking | McKinsey: The future of AI is changing rapidly for the banking and financial services industry. We look at how to choose the best operating model to scale your business.\n",
            "- How Will AI Impact Finance? New Research Uncovers Key Findings - Forbes: New research commissioned by SAP Insights identifies macro trends affecting finance organizations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "user_prompt = \"search when do the olympics start?\"\n",
        "result = run_conversation(user_prompt)\n",
        "print(\"Final Response:\", result[\"final_response\"])\n",
        "print(\"\\nTool Outputs:\")\n",
        "for output in result[\"tool_outputs\"]:\n",
        "    print(f\"\\nTool: {output['tool']}\")\n",
        "    print(f\"Query: {output['query']}\")\n",
        "    print(f\"Result: {output['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKKwDyLbvXTT",
        "outputId": "40fd9f6d-83da-426e-c1b0-69f9f5431259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using DuckDuckGo for When do the Olympics start\n",
            "Final Response: The 2024 Paris Olympics are scheduled to start on July 26, 2024, with the opening ceremony along the Seine River. The first events, rugby and soccer, will take place on July 24, 2024. The games will end on August 11, 2024.\n",
            "\n",
            "Tool Outputs:\n",
            "\n",
            "Tool: internet_search\n",
            "Query: When do the Olympics start\n",
            "Result: Here are some search results for 'When do the Olympics start':\n",
            "- Paris 2024 - Olympics.com: Please note the competition schedule is subject to change until the conclusion of the Olympic Games. The surfing competition will be held over 4 days within a period of 9 days, depending on the weather conditions. Timing and Scoring provided by Omega / Official Results powered by Atos. Official Paris 2024 Olympic schedule.\n",
            "- Paris 2024 Olympic Games full schedule and day-by-day competitions: Find out when and where your favourite sports and events are happening at the Olympic Games Paris 2024. The Games start on 26 July and end on 11 August 2024, with the Opening and Closing Ceremonies in between.\n",
            "- When do the Olympics start? Full schedule, dates, times for 2024 Summer ...: The 2024 Summer Olympics will take place from July 24 to August 11 in Paris, France. The opening ceremony will be held on July 26 along the Seine River, and the first events will be rugby and soccer on July 24.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2w0nErF7x2cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJBHqoAhx2fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nq6irVygx2jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VHK9-1Hcx2mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDyLwBUQx2qX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}